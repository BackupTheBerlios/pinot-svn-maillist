<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Pinot-svn] r1472 - in trunk: SQL UI/GTK2/src
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/pinot-svn/2009-January/index.html" >
   <LINK REL="made" HREF="mailto:pinot-svn%40lists.berlios.de?Subject=Re%3A%20%5BPinot-svn%5D%20r1472%20-%20in%20trunk%3A%20SQL%20UI/GTK2/src&In-Reply-To=%3C200901101524.n0AFObg9031653%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001461.html">
   <LINK REL="Next"  HREF="001463.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Pinot-svn] r1472 - in trunk: SQL UI/GTK2/src</H1>
    <B>fabricecolin at mail.berlios.de</B> 
    <A HREF="mailto:pinot-svn%40lists.berlios.de?Subject=Re%3A%20%5BPinot-svn%5D%20r1472%20-%20in%20trunk%3A%20SQL%20UI/GTK2/src&In-Reply-To=%3C200901101524.n0AFObg9031653%40sheep.berlios.de%3E"
       TITLE="[Pinot-svn] r1472 - in trunk: SQL UI/GTK2/src">fabricecolin at mail.berlios.de
       </A><BR>
    <I>Sat Jan 10 16:24:37 CET 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="001461.html">[Pinot-svn] r1471 - trunk/IndexSearch/Xapian
</A></li>
        <LI>Next message: <A HREF="001463.html">[Pinot-svn] r1473 - trunk
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1462">[ date ]</a>
              <a href="thread.html#1462">[ thread ]</a>
              <a href="subject.html#1462">[ subject ]</a>
              <a href="author.html#1462">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: fabricecolin
Date: 2009-01-10 16:24:26 +0100 (Sat, 10 Jan 2009)
New Revision: 1472

Modified:
   trunk/SQL/CrawlHistory.cpp
   trunk/SQL/CrawlHistory.h
   trunk/UI/GTK2/src/ServerThreads.cpp
   trunk/UI/GTK2/src/ServerThreads.h
   trunk/UI/GTK2/src/WorkerThreads.cpp
Log:
Don't skip outright locations that already have a CrawlHistory entry, this would
prevent resuming gracefully if the previous indexing run stopped before
completion.
Keep track of symlinks we follow, and skip those that refer to locations that
have been crawled (they have a CrawlHistory entry of any type) or that we know
will be crawled because they are under an indexable location. Once a symlink is
followed, if we end up back in one of the indexable locations, symlinks found
there will be skipped.
Skipped symlinks are indexed on their own with MIME type &quot;inode/symlink&quot;.
In IndexingThread, avoid downloading unnecessarily documents for which an
unsupported MIME type is supplied by the caller.


Modified: trunk/SQL/CrawlHistory.cpp
===================================================================
--- trunk/SQL/CrawlHistory.cpp	2009-01-10 14:50:55 UTC (rev 1471)
+++ trunk/SQL/CrawlHistory.cpp	2009-01-10 15:24:26 UTC (rev 1472)
@@ -61,6 +61,9 @@
 		case CRAWL_ERROR:
 			text = &quot;ERROR&quot;;
 			break;
+		case CRAWL_LINK:
+			text = &quot;LINK&quot;;
+			break;
 		default:
 			break;
 	}
@@ -88,6 +91,10 @@
 	{
 		status = CRAWL_ERROR;
 	}
+	else if (text == &quot;LINK&quot;)
+	{
+		status = CRAWL_LINK;
+	}
 
 	return status;
 }

Modified: trunk/SQL/CrawlHistory.h
===================================================================
--- trunk/SQL/CrawlHistory.h	2009-01-10 14:50:55 UTC (rev 1471)
+++ trunk/SQL/CrawlHistory.h	2009-01-10 15:24:26 UTC (rev 1472)
@@ -33,7 +33,7 @@
 		CrawlHistory(const std::string &amp;database);
 		virtual ~CrawlHistory();
 
-		typedef enum { UNKNOWN, TO_CRAWL, CRAWLING, CRAWLED, CRAWL_ERROR } CrawlStatus;
+		typedef enum { UNKNOWN, TO_CRAWL, CRAWLING, CRAWLED, CRAWL_ERROR, CRAWL_LINK } CrawlStatus;
 
 		/// Creates the CrawlHistory table in the database.
 		static bool create(const std::string &amp;database);

Modified: trunk/UI/GTK2/src/ServerThreads.cpp
===================================================================
--- trunk/UI/GTK2/src/ServerThreads.cpp	2009-01-10 14:50:55 UTC (rev 1471)
+++ trunk/UI/GTK2/src/ServerThreads.cpp	2009-01-10 15:24:26 UTC (rev 1472)
@@ -272,12 +272,39 @@
 	}
 }
 
-bool DirectoryScannerThread::scanEntry(const string &amp;entryName, CrawlHistory &amp;crawlHistory)
+bool DirectoryScannerThread::isIndexable(const string &amp;entryName) const
 {
+	string entryDir(path_get_dirname(entryName) + &quot;/&quot;);
+
+	// Is this under one of the locations configured for indexing ?
+	for (set&lt;PinotSettings::IndexableLocation&gt;::const_iterator locationIter = PinotSettings::getInstance().m_indexableLocations.begin();
+		locationIter != PinotSettings::getInstance().m_indexableLocations.end(); ++locationIter)
+	{
+		string locationDir(locationIter-&gt;m_name + &quot;/&quot;);
+
+		if ((entryDir.length() &gt;= locationDir.length()) &amp;&amp;
+			(entryDir.substr(0, locationDir.length()) == locationDir))
+		{
+			// Yes, it is
+#ifdef DEBUG
+			cout &lt;&lt; &quot;DirectoryScannerThread::isIndexable: under &quot; &lt;&lt; locationDir &lt;&lt; endl;
+#endif
+			return true;
+		}
+	}
+
+	return false;
+}
+
+bool DirectoryScannerThread::scanEntry(const string &amp;entryName, CrawlHistory &amp;crawlHistory,
+	bool statLinks)
+{
 	string location(&quot;<A HREF="file://">file://</A>&quot; + entryName);
+	DocumentInfo docInfo(&quot;&quot;, location, &quot;&quot;, &quot;&quot;);
 	CrawlHistory::CrawlStatus itemStatus = CrawlHistory::UNKNOWN;
-	time_t itemDate;
+	time_t itemDate = time(NULL);
 	struct stat fileStat;
+	int entryStatus = 0;
 	bool scanSuccess = true, reportFile = false, itemExists = false;
 
 	if (entryName.empty() == true)
@@ -301,26 +328,16 @@
 	cout &lt;&lt; &quot;DirectoryScannerThread::scanEntry: checking &quot; &lt;&lt; entryName &lt;&lt; endl;
 #endif
 
-	// Is this item in the database already ?
-	itemExists = crawlHistory.hasItem(location, itemStatus, itemDate);
-	if (itemExists == true)
+	// Stat links, or the stuff it refers to ?
+	if (statLinks == true)
 	{
-		if (itemStatus &gt; CrawlHistory::TO_CRAWL)
-		{
-			// At this stage, this shouldn't happen
-			cout &lt;&lt; &quot;Skipping &quot; &lt;&lt; entryName &lt;&lt; &quot;: it has already been crawled&quot; &lt;&lt; endl;
-			return false;
-		}
-
-		crawlHistory.updateItem(location, CrawlHistory::CRAWLING, itemDate);
+		entryStatus = lstat(entryName.c_str(), &amp;fileStat);
 	}
 	else
 	{
-		// Record it
-		crawlHistory.insertItem(location, CrawlHistory::CRAWLING, m_sourceId, itemDate);
+		entryStatus = stat(entryName.c_str(), &amp;fileStat);
 	}
 
-	int entryStatus = lstat(entryName.c_str(), &amp;fileStat);
 	if (entryStatus == -1)
 	{
 		entryStatus = errno;
@@ -329,10 +346,12 @@
 		cout &lt;&lt; &quot;DirectoryScannerThread::scanEntry: stat failed with error &quot; &lt;&lt; entryStatus &lt;&lt; endl;
 #endif
 	}
-	// Is it a file or a directory ?
+	// Special processing applies if it's a symlink
 	else if (S_ISLNK(fileStat.st_mode))
 	{
-		string trueEntryName;
+		string realEntryName(entryName);
+		string entryNameReferree;
+		bool isInIndexableLocation = false;
 
 		if (m_followSymLinks == false)
 		{
@@ -342,17 +361,35 @@
 			return false;
 		}
 
-		char *pBuf = g_file_read_link(entryName.c_str(), NULL);
+		// Are we already following a symlink to a directory ?
+		if (m_currentLinks.empty() == false)
+		{
+			string linkToDir(m_currentLinks.top() + &quot;/&quot;);
+
+			// Yes, we are
+			if ((entryName.length() &gt; linkToDir.length()) &amp;&amp;
+				(entryName.substr(0, linkToDir.length()) == linkToDir))
+			{
+				// ...and this entry is below it
+				realEntryName.replace(0, linkToDir.length() - 1, m_currentLinkReferrees.top());
+#ifdef DEBUG
+				cout &lt;&lt; &quot;DirectoryScannerThread::scanEntry: really at &quot; &lt;&lt; realEntryName &lt;&lt; endl;
+#endif
+				isInIndexableLocation = isIndexable(realEntryName);
+			}
+		}
+
+		char *pBuf = g_file_read_link(realEntryName.c_str(), NULL);
 		if (pBuf != NULL)
 		{
 			string linkLocation(filename_to_utf8(pBuf));
 			if (path_is_absolute(linkLocation) == true)
 			{
-				trueEntryName = linkLocation;
+				entryNameReferree = linkLocation;
 			}
 			else
 			{
-				string entryDir(path_get_dirname(entryName));
+				string entryDir(path_get_dirname(realEntryName));
 				string::size_type prevSlashPos = 0, slashPos = linkLocation.find('/');
 
 				while (slashPos != string::npos)
@@ -370,7 +407,7 @@
 						entryDir += path;
 					}
 #ifdef DEBUG
-					cout &lt;&lt; &quot;DirectoryScannerThread::scanEntry: symlink resolved to &quot; &lt;&lt; entryDir &lt;&lt; endl;
+					cout &lt;&lt; &quot;DirectoryScannerThread::scanEntry: symlink partially resolved to &quot; &lt;&lt; entryDir &lt;&lt; endl;
 #endif
 
 					if (slashPos + 1 &gt;= linkLocation.length())
@@ -401,34 +438,76 @@
 						entryDir += path;
 					}
 				}
+
+				entryNameReferree = entryDir;
+			}
+
+			if (entryNameReferree[entryNameReferree.length() - 1] == '/')
+			{
+				// Drop the terminating slash
+				entryNameReferree.resize(entryNameReferree.length() - 1);
+			}
 #ifdef DEBUG
-				cout &lt;&lt; &quot;DirectoryScannerThread::scanEntry: symlink resolved to &quot; &lt;&lt; entryDir &lt;&lt; endl;
+			cout &lt;&lt; &quot;DirectoryScannerThread::scanEntry: symlink resolved to &quot; &lt;&lt; entryNameReferree &lt;&lt; endl;
 #endif
 
-				trueEntryName = entryDir;
-			}
-
 			g_free(pBuf);
 		}
 
-		string trueLocation(&quot;<A HREF="file://">file://</A>&quot; + trueEntryName);
-		CrawlHistory::CrawlStatus trueItemStatus = CrawlHistory::UNKNOWN;
-		time_t trueItemDate;
+		string referreeLocation(&quot;<A HREF="file://">file://</A>&quot; + entryNameReferree);
+		CrawlHistory::CrawlStatus referreeItemStatus = CrawlHistory::UNKNOWN;
+		time_t referreeItemDate;
 
 		// Check whether this will be, or has already been crawled
-		if (crawlHistory.hasItem(trueLocation, trueItemStatus, trueItemDate) == false)
+		// Referrees in indexable locations will be indexed later on
+		if ((isInIndexableLocation == false) &amp;&amp;
+			(isIndexable(entryNameReferree) == false) &amp;&amp;
+			(crawlHistory.hasItem(referreeLocation, referreeItemStatus, referreeItemDate) == false))
 		{
-			if (PinotSettings::getInstance().isBlackListed(entryName) == false)
-			{
-				// Proceed as per regular files
-				reportFile = true;
-			}
+			m_currentLinks.push(entryName);
+			m_currentLinkReferrees.push(entryNameReferree);
+
+			// Add a dummy entry for this referree
+			// It will ensure it's not indexed more than once and it shouldn't do any harm
+			crawlHistory.insertItem(referreeLocation, CrawlHistory::CRAWL_LINK, m_sourceId, itemDate);
+
+			// Do it again, this time by stat'ing what the link refers to
+			scanEntry(entryName, crawlHistory, false);
+
+			m_currentLinks.pop();
+			m_currentLinkReferrees.pop();
 		}
-		else cout &lt;&lt; &quot;Skipping &quot; &lt;&lt; entryName &lt;&lt; &quot;: it links to &quot; &lt;&lt; trueEntryName
-			&lt;&lt; &quot; which will be crawled, or has already been crawled&quot; &lt;&lt; endl;
+		else
+		{
+			cout &lt;&lt; &quot;Skipping &quot; &lt;&lt; entryName &lt;&lt; &quot;: it links to &quot; &lt;&lt; entryNameReferree
+				&lt;&lt; &quot; which will be crawled, or has already been crawled&quot; &lt;&lt; endl;
+
+			// This should ensure that only metadata is indexed
+			docInfo.setType(&quot;inode/symlink&quot;);
+			reportFile = true;
+		}
 	}
-	else if (S_ISREG(fileStat.st_mode))
+
+	// Is this item in the database already ?
+	itemExists = crawlHistory.hasItem(location, itemStatus, itemDate);
+	if (itemExists == true)
 	{
+		if (m_fullScan == true)
+		{
+			// Change the status from TO_CRAWL to CRAWLING
+			crawlHistory.updateItem(location, CrawlHistory::CRAWLING, itemDate);
+		}
+	}
+	else
+	{
+		// Record it
+		crawlHistory.insertItem(location, CrawlHistory::CRAWLING, m_sourceId, itemDate);
+	}
+
+	// If stat'ing didn't fail, see if it's a file or a directory
+	if ((entryStatus == 0) &amp;&amp;
+		(S_ISREG(fileStat.st_mode)))
+	{
 		// Is this file blacklisted ?
 		// We have to check early so that if necessary the file's status stays at TO_CRAWL
 		// and it is removed from the index at the end of this crawl
@@ -437,8 +516,11 @@
 			reportFile = true;
 		}
 	}
-	else if (S_ISDIR(fileStat.st_mode))
+	else if ((entryStatus == 0) &amp;&amp;
+		(S_ISDIR(fileStat.st_mode)))
 	{
+		docInfo.setType(&quot;x-directory/normal&quot;);
+
 		// Can we scan this directory ?
 		if (((m_maxLevel == 0) ||
 			(m_currentLevel &lt; m_maxLevel)) &amp;&amp;
@@ -509,7 +591,9 @@
 			}
 		}
 	}
-	else
+	// Is it some unknown type ?
+	else if ((entryStatus == 0) &amp;&amp;
+		(!S_ISLNK(fileStat.st_mode)))
 	{
 #ifdef DEBUG
 		cout &lt;&lt; &quot;DirectoryScannerThread::scanEntry: unknown entry type&quot; &lt;&lt; endl;
@@ -518,53 +602,12 @@
 		scanSuccess = false;
 	}
 
-	// If a major error occured, this won't be true
-	if (reportFile == true)
+	// Was it modified after the last crawl ?
+	if ((itemExists == true) &amp;&amp;
+		(itemDate &gt;= fileStat.st_mtime))
 	{
-		// Was it modified after the last crawl ?
-		if ((itemExists == true) &amp;&amp;
-			(itemDate &gt;= fileStat.st_mtime))
-		{
-			// No, it wasn't
-			reportFile = false;
-		}
-
-		// History of modified files, especially the timestamp, is always updated
-		// Others' are updated only if we are doing a full scan because
-		// the status has to be reset to CRAWLED, so that they are not unindexed
-		if ((reportFile == true) ||
-			(m_fullScan == true))
-		{
-#ifdef DEBUG
-			cout &lt;&lt; &quot;DirectoryScannerThread::scanEntry: updating &quot; &lt;&lt; entryName &lt;&lt; endl;
-#endif
-			cacheUpdate(location, fileStat.st_mtime, crawlHistory);
-		}
-
-		if (reportFile == true)
-		{
-			DocumentInfo docInfo(&quot;&quot;, location, &quot;&quot;, &quot;&quot;);
-			set&lt;string&gt; labels;
-			stringstream labelStream;
-
-			if (S_ISDIR(fileStat.st_mode))
-			{
-				docInfo.setType(&quot;x-directory/normal&quot;);
-			}
-			else
-			{
-				// We might as well scan the file for its type now
-				docInfo.setType(MIMEScanner::scanFile(entryName));
-			}
-			docInfo.setTimestamp(TimeConverter::toTimestamp(fileStat.st_mtime));
-			docInfo.setSize(fileStat.st_size);
-			// Insert a label that identifies the source
-			labelStream &lt;&lt; &quot;X-SOURCE&quot; &lt;&lt; m_sourceId;
-			labels.insert(labelStream.str());
-			docInfo.setLabels(labels);
-
-			foundFile(docInfo);
-		}
+		// No, it wasn't
+		reportFile = false;
 	}
 
 	// Did an error occur ?
@@ -574,8 +617,47 @@
 
 		// Record this error
 		crawlHistory.updateItem(location, CrawlHistory::CRAWL_ERROR, timeNow, entryStatus);
+
+		if (scanSuccess == false)
+		{
+			return scanSuccess;
+		}
 	}
+	// History of new or modified files, especially their timestamp, is always updated
+	// Others' are updated only if we are doing a full scan because
+	// the status has to be reset to CRAWLED, so that they are not unindexed
+	else if ((itemExists == false) ||
+		(reportFile == true) ||
+		(m_fullScan == true))
+	{
+#ifdef DEBUG
+		cout &lt;&lt; &quot;DirectoryScannerThread::scanEntry: updating &quot; &lt;&lt; entryName &lt;&lt; endl;
+#endif
+		cacheUpdate(location, fileStat.st_mtime, crawlHistory);
+	}
 
+	// If a major error occured, this won't be true
+	if (reportFile == true)
+	{
+		set&lt;string&gt; labels;
+		stringstream labelStream;
+
+		if (docInfo.getType().empty() == true)
+		{
+			// Scan the file
+			docInfo.setType(MIMEScanner::scanFile(entryName));
+		}
+		docInfo.setTimestamp(TimeConverter::toTimestamp(fileStat.st_mtime));
+		docInfo.setSize(fileStat.st_size);
+
+		// Insert a label that identifies the source
+		labelStream &lt;&lt; &quot;X-SOURCE&quot; &lt;&lt; m_sourceId;
+		labels.insert(labelStream.str());
+		docInfo.setLabels(labels);
+
+		foundFile(docInfo);
+	}
+
 	return scanSuccess;
 }
 
@@ -610,6 +692,7 @@
 		m_errorParam = m_dirName;
 	}
 	flushUpdates(crawlHistory);
+	crawlHistory.deleteItems(m_sourceId, CrawlHistory::CRAWL_LINK);
 	cout &lt;&lt; &quot;Scanned &quot; &lt;&lt; m_dirName &lt;&lt; &quot; in &quot; &lt;&lt; scanTimer.stop() &lt;&lt; &quot; ms&quot; &lt;&lt; endl;
 
 	if (m_done == true)

Modified: trunk/UI/GTK2/src/ServerThreads.h
===================================================================
--- trunk/UI/GTK2/src/ServerThreads.h	2009-01-10 14:50:55 UTC (rev 1471)
+++ trunk/UI/GTK2/src/ServerThreads.h	2009-01-10 15:24:26 UTC (rev 1472)
@@ -1,5 +1,5 @@
 /*
- *  Copyright 2005-2008 Fabrice Colin
+ *  Copyright 2005-2009 Fabrice Colin
  *
  *  This program is free software; you can redistribute it and/or modify
  *  it under the terms of the GNU General Public License as published by
@@ -21,6 +21,7 @@
 
 #include &lt;string&gt;
 #include &lt;vector&gt;
+#include &lt;stack&gt;
 #include &lt;sigc++/sigc++.h&gt;
 #include &lt;glibmm/ustring.h&gt;
 
@@ -62,11 +63,15 @@
 		bool m_delegateIndexing;
 		sigc::signal2&lt;void, DocumentInfo, bool&gt; m_signalFileFound;
 		std::map&lt;std::string, time_t&gt; m_updateCache;
+		std::stack&lt;std::string&gt; m_currentLinks;
+		std::stack&lt;std::string&gt; m_currentLinkReferrees;
 
 		void cacheUpdate(const std::string &amp;location, time_t mTime, CrawlHistory &amp;crawlHistory);
 		void flushUpdates(CrawlHistory &amp;crawlHistory);
 		void foundFile(const DocumentInfo &amp;docInfo);
-		bool scanEntry(const std::string &amp;entryName, CrawlHistory &amp;crawlHistory);
+		bool isIndexable(const std::string &amp;entryName) const;
+		bool scanEntry(const std::string &amp;entryName, CrawlHistory &amp;crawlHistory,
+			bool statLinks = true);
 		virtual void doWork(void);
 
 	private:

Modified: trunk/UI/GTK2/src/WorkerThreads.cpp
===================================================================
--- trunk/UI/GTK2/src/WorkerThreads.cpp	2009-01-10 14:50:55 UTC (rev 1471)
+++ trunk/UI/GTK2/src/WorkerThreads.cpp	2009-01-10 15:24:26 UTC (rev 1472)
@@ -1,5 +1,5 @@
 /*
- *  Copyright 2005-2008 Fabrice Colin
+ *  Copyright 2005-2009 Fabrice Colin
  *
  *  This program is free software; you can redistribute it and/or modify
  *  it under the terms of the GNU General Public License as published by
@@ -1551,7 +1551,7 @@
 {
 	IndexInterface *pIndex = PinotSettings::getInstance().getIndex(m_indexLocation);
 	Url thisUrl(m_docInfo.getLocation());
-	bool doDownload = true;
+	bool reliableType = false, doDownload = true;
 
 	// First things first, get the index
 	if ((pIndex == NULL) ||
@@ -1574,12 +1574,15 @@
 		m_update = true;
 	}
 
-	// We may not have to download the document
-	// If coming from a crawl, this will be empty
 	if (m_docInfo.getType().empty() == true)
 	{
 		m_docInfo.setType(MIMEScanner::scanUrl(thisUrl));
 	}
+	else
+	{
+		// There's a good chance the supplied type is accurate
+		reliableType = true;
+	}
 
 	if (FilterUtils::isSupportedType(m_docInfo.getType()) == false)
 	{
@@ -1592,6 +1595,14 @@
 
 			return;
 		}
+
+		if (reliableType == true)
+		{
+			doDownload = false;
+#ifdef DEBUG
+			cout &lt;&lt; &quot;IndexingThread::doWork: skipping download of unsupported type &quot; &lt;&lt; m_docInfo.getLocation() &lt;&lt; endl;
+#endif
+		}
 	}
 	else
 	{
@@ -1606,12 +1617,16 @@
 				(thisUrl.isLocal() == false)))
 			{
 				doDownload = false;
+#ifdef DEBUG
+				cout &lt;&lt; &quot;IndexingThread::doWork: let filter download &quot; &lt;&lt; m_docInfo.getLocation() &lt;&lt; endl;
+#endif
 			}
 
 			delete pFilter;
 		}
 	}
 
+	// We may not have to download the document
 	if (doDownload == true)
 	{
 		DownloadingThread::doWork();
@@ -1622,9 +1637,6 @@
 
 		m_pDoc-&gt;setTimestamp(m_docInfo.getTimestamp());
 		m_pDoc-&gt;setSize(m_docInfo.getSize());
-#ifdef DEBUG
-		cout &lt;&lt; &quot;IndexingThread::doWork: skipped download of &quot; &lt;&lt; m_docInfo.getLocation() &lt;&lt; endl;
-#endif
 	}
 
 	if (m_pDoc != NULL)
@@ -1635,10 +1647,12 @@
 		// The type may have been obtained when downloading
 		if (docType.empty() == false)
 		{
+			// Use the document's type
 			m_docInfo.setType(docType);
 		}
 		else
 		{
+			// Use the type we were supplied with
 			m_pDoc-&gt;setType(m_docInfo.getType());
 		}
 


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001461.html">[Pinot-svn] r1471 - trunk/IndexSearch/Xapian
</A></li>
	<LI>Next message: <A HREF="001463.html">[Pinot-svn] r1473 - trunk
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1462">[ date ]</a>
              <a href="thread.html#1462">[ thread ]</a>
              <a href="subject.html#1462">[ subject ]</a>
              <a href="author.html#1462">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/pinot-svn">More information about the Pinot-svn
mailing list</a><br>
</body></html>
