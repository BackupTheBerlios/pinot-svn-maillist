<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Pinot-svn] r285 - trunk/Tokenize
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/pinot-svn/2006-June/index.html" >
   <LINK REL="made" HREF="mailto:pinot-svn%40lists.berlios.de?Subject=Re%3A%20%5BPinot-svn%5D%20r285%20-%20trunk/Tokenize&In-Reply-To=%3C200606021357.k52Dv9iq023466%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000278.html">
   <LINK REL="Next"  HREF="000280.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Pinot-svn] r285 - trunk/Tokenize</H1>
    <B>fabricecolin at BerliOS</B> 
    <A HREF="mailto:pinot-svn%40lists.berlios.de?Subject=Re%3A%20%5BPinot-svn%5D%20r285%20-%20trunk/Tokenize&In-Reply-To=%3C200606021357.k52Dv9iq023466%40sheep.berlios.de%3E"
       TITLE="[Pinot-svn] r285 - trunk/Tokenize">fabricecolin at berlios.de
       </A><BR>
    <I>Fri Jun  2 15:57:09 CEST 2006</I>
    <P><UL>
        <LI>Previous message: <A HREF="000278.html">[Pinot-svn] r284 - in trunk: Search Tokenize
</A></li>
        <LI>Next message: <A HREF="000280.html">[Pinot-svn] r286 - in trunk: Collect UI/GTK2/src
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#279">[ date ]</a>
              <a href="thread.html#279">[ thread ]</a>
              <a href="subject.html#279">[ subject ]</a>
              <a href="author.html#279">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: fabricecolin
Date: 2006-06-02 15:57:08 +0200 (Fri, 02 Jun 2006)
New Revision: 285

Modified:
   trunk/Tokenize/HtmlTokenizer.cpp
   trunk/Tokenize/HtmlTokenizer.h
   trunk/Tokenize/PdfTokenizer.cpp
   trunk/Tokenize/RtfTokenizer.cpp
   trunk/Tokenize/TokenizerFactory.cpp
Log:
Various fixes. HtmlTokenizer can do validation without content extraction.


Modified: trunk/Tokenize/HtmlTokenizer.cpp
===================================================================
--- trunk/Tokenize/HtmlTokenizer.cpp	2006-06-01 11:28:51 UTC (rev 284)
+++ trunk/Tokenize/HtmlTokenizer.cpp	2006-06-02 13:57:08 UTC (rev 285)
@@ -128,13 +128,17 @@
 			{
 				metaContent = pAttributes[attrNum + 1];
 			}
+			else if (strncasecmp(pAttributes[attrNum], &quot;http-equiv&quot;, 10) == 0)
+			{
+				metaName = pAttributes[attrNum + 1];
+			}
 		}
 
 		if ((metaName.empty() == false) &amp;&amp;
 			(metaContent.empty() == false))
 		{
 			// Store this META tag
-			pState-&gt;m_metaTags[metaName] = metaContent;
+			pState-&gt;m_metaTags[StringManip::toLowerCase(metaName)] = metaContent;
 		}
 	}
 	else if ((pState-&gt;m_inHead == true) &amp;&amp;
@@ -169,7 +173,7 @@
 			// FIXME: get the NodeInfo to find out the position of this link
 			pState-&gt;m_currentLink.m_startPos = pState-&gt;m_textPos;
 #ifdef DEBUG
-			cout &lt;&lt; &quot;HtmlTokenizer::parseHTML: link starts at position &quot; &lt;&lt; pState-&gt;m_textPos &lt;&lt; endl;
+			cout &lt;&lt; &quot;HtmlTokenizer::startHandler: link starts at position &quot; &lt;&lt; pState-&gt;m_textPos &lt;&lt; endl;
 #endif
 
 			// Find abstract ?
@@ -255,7 +259,7 @@
 			// FIXME: get the NodeInfo to find out the position of this link
 			pState-&gt;m_currentLink.m_endPos = pState-&gt;m_textPos;
 #ifdef DEBUG
-			cout &lt;&lt; &quot;HtmlTokenizer::parseHTML: link ends at position &quot; &lt;&lt; pState-&gt;m_textPos &lt;&lt; endl;
+			cout &lt;&lt; &quot;HtmlTokenizer::endHandler: link ends at position &quot; &lt;&lt; pState-&gt;m_textPos &lt;&lt; endl;
 #endif
 				
 			// Store this link
@@ -379,6 +383,17 @@
 
 static void errorHandler(void *pData, const char *pMsg, ...)
 {
+	if (pData == NULL)
+	{
+		return;
+	}
+
+	HtmlTokenizer::ParserState *pState = (HtmlTokenizer::ParserState *)pData;
+	if (pState == NULL)
+	{
+		return;
+	}
+
 	va_list args;
 	char pErr[1000];
 
@@ -390,6 +405,8 @@
 
 	// Be lenient as much as possible
 	xmlResetLastError();
+	// ...but remember the document had errors
+	pState-&gt;m_isValid = false;
 }
 
 static void warningHandler(void *pData, const char *pMsg, ...)
@@ -446,6 +463,7 @@
 }
 
 HtmlTokenizer::ParserState::ParserState() :
+	m_isValid(true),
 	m_findAbstract(false),
 	m_textPos(0),
 	m_inHead(false),
@@ -461,44 +479,36 @@
 {
 }
 
-HtmlTokenizer::HtmlTokenizer(const Document *pDocument, bool findAbstract) :
+HtmlTokenizer::HtmlTokenizer(const Document *pDocument,
+	bool validateOnly, bool findAbstract) :
 	Tokenizer(NULL)
 {
-	if (pDocument != NULL)
+	if (validateOnly == true)
 	{
-		unsigned int length = 0;
-		const char *pData = pDocument-&gt;getData(length);
-
+		// This will ensure text is skipped
+		++m_state.m_skip;
+	}
+	else
+	{
 		// Attempt to find an abstract ?
 		m_state.m_findAbstract = findAbstract;
+	}
 
-		if ((pData != NULL) &amp;&amp;
-			(length &gt; 0) &amp;&amp;
-			(parseHTML(pData) == true))
+	if (parseHTML(pDocument) == true)
+	{
+		// Did we find a title ?
+		if (m_state.m_title.empty() == true)
 		{
-			// Append META keywords, if any were found
-			m_state.m_text += getMetaTag(&quot;keywords&quot;);
+			m_state.m_title = pDocument-&gt;getTitle();
+		}
 
-			// Did we find a title ?
-			if (m_state.m_title.empty() == true)
-			{
-				m_state.m_title = pDocument-&gt;getTitle();
-			}
+		// Pass the result to the parent class
+		Document *pStrippedDoc = new Document(m_state.m_title,
+			pDocument-&gt;getLocation(), pDocument-&gt;getType(),
+			pDocument-&gt;getLanguage());
+		pStrippedDoc-&gt;setData(m_state.m_text.c_str(), m_state.m_text.length());
 
-			// The text after the last link might make a good abstract
-			if (m_state.m_findAbstract == true)
-			{
-				getInBetweenLinksText(&amp;m_state, m_state.m_currentLink.m_index);
-			}
-
-			// Pass the result to the parent class
-			Document *pStrippedDoc = new Document(m_state.m_title,
-				pDocument-&gt;getLocation(), pDocument-&gt;getType(),
-				pDocument-&gt;getLanguage());
-			pStrippedDoc-&gt;setData(m_state.m_text.c_str(), m_state.m_text.length());
-
-			setDocument(pStrippedDoc);
-		}
+		setDocument(pStrippedDoc);
 	}
 }
 
@@ -506,18 +516,22 @@
 {
 	if (m_pDocument != NULL)
 	{
-		// This should have been set by setDocument(),
-		// called in initialize()
+		// This should have been set by setDocument()
 		delete m_pDocument;
 	}
 }
 
-bool HtmlTokenizer::parseHTML(const string &amp;str)
+bool HtmlTokenizer::parseHTML(const Document *pDocument)
 {
-	string htmlChunk(str);
-	htmlSAXHandler saxHandler;
+	if (pDocument == NULL)
+	{
+		return false;
+	}
 
-	if (str.empty() == true)
+	unsigned int dataLength = 0;
+	const char *pData = pDocument-&gt;getData(dataLength);
+	if ((pData == NULL) ||
+		(dataLength == 0))
 	{
 #ifdef DEBUG
 		cout &lt;&lt; &quot;HtmlTokenizer::parseHTML: no input&quot; &lt;&lt; endl;
@@ -525,6 +539,9 @@
 		return false;
 	}
 
+	string htmlChunk(pData, dataLength);
+	htmlSAXHandler saxHandler;
+
 	xmlInitParser();
 
 	// Setup the SAX handler
@@ -554,20 +571,6 @@
 #endif
 	}
 
-	// Wrap input with a dummy tag to avoid the characters handler being called with twice the same text
-	htmlPos = htmlChunk.find(&quot;&lt;HTML&quot;);
-	if (htmlPos == string::npos)
-	{
-		htmlPos = htmlChunk.find(&quot;&lt;html&quot;);
-	}
-	if (htmlPos == string::npos)
-	{
-		string dummyHtml(&quot;&lt;html&gt;&quot;);
-		dummyHtml += htmlChunk;
-		dummyHtml += &quot;&lt;/html&gt;&quot;;
-		htmlChunk = dummyHtml;
-	}
-
 #ifndef _DONT_USE_PUSH_INTERFACE
 	htmlParserCtxtPtr pContext = htmlCreatePushParserCtxt(&amp;saxHandler, (void*)&amp;m_state,
 		htmlChunk.c_str(), (int)htmlChunk.length(), &quot;&quot;, XML_CHAR_ENCODING_NONE);
@@ -593,9 +596,24 @@
 	}
 	xmlCleanupParser();
 
+	// The text after the last link might make a good abstract
+	if (m_state.m_findAbstract == true)
+	{
+		getInBetweenLinksText(&amp;m_state, m_state.m_currentLink.m_index);
+	}
+
+	// Append META keywords, if any were found
+	m_state.m_text += getMetaTag(&quot;keywords&quot;);
+
 	return true;
 }
 
+/// Determines whether the document is properly formed.
+bool HtmlTokenizer::isDocumentValid(void) const
+{
+	return m_state.m_isValid;
+}
+
 /// Gets the specified META tag content.
 string HtmlTokenizer::getMetaTag(const string &amp;name) const
 {
@@ -604,7 +622,7 @@
 		return &quot;&quot;;
 	}
 
-	map&lt;string, string&gt;::const_iterator iter = m_state.m_metaTags.find(name);
+	map&lt;string, string&gt;::const_iterator iter = m_state.m_metaTags.find(StringManip::toLowerCase(name));
 	if (iter != m_state.m_metaTags.end())
 	{
 		return iter-&gt;second;

Modified: trunk/Tokenize/HtmlTokenizer.h
===================================================================
--- trunk/Tokenize/HtmlTokenizer.h	2006-06-01 11:28:51 UTC (rev 284)
+++ trunk/Tokenize/HtmlTokenizer.h	2006-06-02 13:57:08 UTC (rev 285)
@@ -47,9 +47,13 @@
 class HtmlTokenizer : public Tokenizer
 {
 	public:
-		HtmlTokenizer(const Document *pDocument, bool findAbstract = false);
+		HtmlTokenizer(const Document *pDocument,
+			bool validateOnly, bool findAbstract = false);
 		virtual ~HtmlTokenizer();
 
+		/// Determines whether the document is properly formed.
+		bool isDocumentValid(void) const;
+
 		/// Gets the specified META tag content; an empty string if it wasn't found.
 		std::string getMetaTag(const std::string &amp;name) const;
 
@@ -65,6 +69,7 @@
 				ParserState();
 				~ParserState();
 
+				bool m_isValid;
 				bool m_findAbstract;
 				unsigned int m_textPos;
 				std::string m_lastHash;
@@ -85,8 +90,10 @@
 
 	protected:
 		ParserState m_state;
+		bool m_isFragment;
+		std::string m_charset;
 
-		bool parseHTML(const std::string &amp;str);
+		bool parseHTML(const Document *pDocument);
 
 };
 

Modified: trunk/Tokenize/PdfTokenizer.cpp
===================================================================
--- trunk/Tokenize/PdfTokenizer.cpp	2006-06-01 11:28:51 UTC (rev 284)
+++ trunk/Tokenize/PdfTokenizer.cpp	2006-06-02 13:57:08 UTC (rev 285)
@@ -38,8 +38,24 @@
 }
 
 PdfTokenizer::PdfTokenizer(const Document *pDocument) :
-	HtmlTokenizer(runHelperProgram(pDocument, &quot;pdftohtml -stdout&quot;))
+	HtmlTokenizer(NULL, false)
 {
+	Document *pHtmlDocument = runHelperProgram(pDocument, &quot;pdftohtml -stdout&quot;);
+	if (pHtmlDocument != NULL)
+	{
+		if (parseHTML(pHtmlDocument) == true)
+		{
+			// Pass the result to the parent class
+			Document *pStrippedDoc = new Document(pHtmlDocument-&gt;getTitle(),
+				pHtmlDocument-&gt;getLocation(), pHtmlDocument-&gt;getType(),
+				pHtmlDocument-&gt;getLanguage());
+			pStrippedDoc-&gt;setData(m_state.m_text.c_str(), m_state.m_text.length());
+
+			setDocument(pStrippedDoc);
+		}
+
+		delete pHtmlDocument;
+	}
 }
 
 PdfTokenizer::~PdfTokenizer()

Modified: trunk/Tokenize/RtfTokenizer.cpp
===================================================================
--- trunk/Tokenize/RtfTokenizer.cpp	2006-06-01 11:28:51 UTC (rev 284)
+++ trunk/Tokenize/RtfTokenizer.cpp	2006-06-02 13:57:08 UTC (rev 285)
@@ -39,8 +39,24 @@
 }
 
 RtfTokenizer::RtfTokenizer(const Document *pDocument) :
-	HtmlTokenizer(runHelperProgram(pDocument, &quot;unrtf --nopict --html&quot;))
+	HtmlTokenizer(NULL, false)
 {
+	Document *pHtmlDocument = runHelperProgram(pDocument, &quot;unrtf --nopict --html&quot;);
+	if (pHtmlDocument != NULL)
+	{
+		if (parseHTML(pHtmlDocument) == true)
+		{
+			// Pass the result to the parent class
+			Document *pStrippedDoc = new Document(pHtmlDocument-&gt;getTitle(),
+				pHtmlDocument-&gt;getLocation(), pHtmlDocument-&gt;getType(),
+				pHtmlDocument-&gt;getLanguage());
+			pStrippedDoc-&gt;setData(m_state.m_text.c_str(), m_state.m_text.length());
+
+			setDocument(pStrippedDoc);
+		}
+
+		delete pHtmlDocument;
+	}
 }
 
 RtfTokenizer::~RtfTokenizer()

Modified: trunk/Tokenize/TokenizerFactory.cpp
===================================================================
--- trunk/Tokenize/TokenizerFactory.cpp	2006-06-01 11:28:51 UTC (rev 284)
+++ trunk/Tokenize/TokenizerFactory.cpp	2006-06-02 13:57:08 UTC (rev 285)
@@ -240,7 +240,7 @@
 
 	if (typeOnly == &quot;text/html&quot;)
 	{
-		return new HtmlTokenizer(pDocument);
+		return new HtmlTokenizer(pDocument, false);
 	}
 	else if (typeOnly == &quot;text/plain&quot;)
 	{


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000278.html">[Pinot-svn] r284 - in trunk: Search Tokenize
</A></li>
	<LI>Next message: <A HREF="000280.html">[Pinot-svn] r286 - in trunk: Collect UI/GTK2/src
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#279">[ date ]</a>
              <a href="thread.html#279">[ thread ]</a>
              <a href="subject.html#279">[ subject ]</a>
              <a href="author.html#279">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/pinot-svn">More information about the Pinot-svn
mailing list</a><br>
</body></html>
